# 環境變數設定

## LLM Provider 設定

### 雲端 LLM (擇一設定)

```bash
# Anthropic Claude (推薦)
ANTHROPIC_API_KEY=sk-ant-xxxxx
ANTHROPIC_MODEL=claude-sonnet-4-20250514  # 可選

# OpenAI
OPENAI_API_KEY=sk-xxxxx
OPENAI_MODEL=gpt-4o  # 可選
```

### 本機 LLM (無需 API Key)

```bash
# LM Studio (預設 http://localhost:1234)
USE_LMSTUDIO=true
LMSTUDIO_BASE_URL=http://localhost:1234/v1  # 可選
LMSTUDIO_MODEL=local-model  # 可選

# Ollama (預設 http://localhost:11434)
USE_OLLAMA=true
OLLAMA_BASE_URL=http://localhost:11434  # 可選
OLLAMA_MODEL=llama3.2  # 可選
```

## Provider 優先順序

1. Anthropic (如果有 ANTHROPIC_API_KEY)
2. OpenAI (如果有 OPENAI_API_KEY)
3. LM Studio (如果設定 USE_LMSTUDIO=true)
4. Ollama (預設，如果服務正在運行)

## Supabase 設定

```bash
NEXT_PUBLIC_SUPABASE_URL=https://xxxxx.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=xxxxx
```
